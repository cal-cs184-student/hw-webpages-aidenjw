<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Names: Aiden Wang, Kelly Tou </div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-aidenjw/hw1/index.html">cal-cs184-student.github.io/hw-webpages-aidenjw/hw1/index.html</a>
		
		<br>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/hw-webpages-aidenjw">github.com/cal-cs184-student/hw-webpages-aidenjw</a>



		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		<p>
			In this homework, we built a rasterizer that takes in SVG primitives and turns them into pixels, adding features
			that improved the functionality. We started with a rasterizer that could draw single-color triangles, then implemented
			supersampling to achieve antialiasing by making the triangle edges noticeable smoother. We then applied
			transforms to pose and recolor Cubeman, teaching us pivot placement and matrix composition for hierarchical modeling.
			We then implemented barycentric coordinates as a tool for interpolating attributes per pixel accross a triangle.
			Using this, we texture mapping with pixel sampling and a mipmap-based level sampling. This helped reduce aliasing due to
			minification. This homework was extremely intimidating at first, especially since we didn't have much prior experience
			with computer graphics. However having the assignment broken down into smaller steps made it much easier to focus and work
			through the problems, and also helped us see how each feature connected with or built upon others. After completing this assignment,
			it makes sense on why we need many different antialiasing techniques, as working on the implementations made us realize how
			each "solution" would only address a specific type of aliasing.
		</p>

		<h2>Task 1: Drawing Single-Color Triangles</h2>
		<h3>Overview</h3>
		<p>
			In this task, I implemented basic triangle rasterization without supersampling. The goal was to determine
			which pixels are covered by a given triangle and color those pixels appropriately.
		</p>
		<p>
			My implementation follows a standard bounding-box and edge-function approach. For each triangle, I:
		</p>
		<ol>
			<li>Compute its axis-aligned bounding box.</li>
			<li>Iterate over all pixel centers inside that bounding box.</li>
			<li>Use edge functions to determine whether each sample lies inside the triangle.</li>
			<li>Fill the pixel if the sample is inside.</li>
		</ol>

		<h3>Bounding Box Computation</h3>
		<p>
			Given triangle vertices <span class="math">\((x0, y0), (x1, y1), (x2, y2)\)</span>, I first compute the smallest
			axis-aligned rectangle that fully contains the triangle:
		</p>
		<ul>
			<li><span class="math">\(min_x = floor(min(x0, x1, x2))\)</span></li>
			<li><span class="math">\(max_x = ceil(max(x0, x1, x2))\)</span></li>
			<li><span class="math">\(min_y = floor(min(y0, y1, y2))\)</span></li>
			<li><span class="math">\(max_y = ceil(max(y0, y1, y2))\)</span></li>
		</ul>
		<p>
			I then clamp these bounds to the framebuffer dimensions
			<span class="math">\([0, width-1]\)</span> and <span class="math">\([0, height-1]\)</span> to avoid out-of-bounds access.
		</p>

		<h3>Edge Function and Point-in-Triangle Test</h3>
		<p>
			To determine whether a sample lies inside the triangle, I use an edge function:
		</p>
		<pre><code>E(a, b, p) = (p - a) × (b - a)</code></pre>
		<p>
			This is the 2D cross product. The sign indicates which side of the directed edge
			<span class="math">\(a → b\)</span> the point <span class="math">\(p\)</span> lies on:
		</p>
		<ul>
			<li><span class="math">\(E &gt; 0\)</span>: point is on the left side</li>
			<li><span class="math">\(E &lt; 0\)</span>: point is on the right side</li>
			<li><span class="math">\(E = 0\)</span>: point lies on the edge</li>
		</ul>

		<p>
			To handle both clockwise and counter-clockwise vertex orderings, I compute the signed double-area:
		</p>
		<pre><code>area2 = E(v0, v1, v2)</code></pre>
		<ul>
			<li><span class="math">\(area2 &gt; 0\)</span>: counter-clockwise</li>
			<li><span class="math">\(area2 &lt; 0\)</span>: clockwise</li>
			<li><span class="math">\(area2 = 0\)</span>: degenerate triangle (skip)</li>
		</ul>

		<p>
			A point is inside the triangle if it lies consistently on the inner side of all three edges, depending
			on the sign of <span class="math">\(area2\)</span>.
		</p>

		<h3>Rasterization Loop</h3>
		<p>
			For every integer pixel coordinate <span class="math">\((x, y)\)</span> inside the bounding box:
		</p>
		<ol>
			<li>Sample at the pixel center <span class="math">\((x + 0.5, y + 0.5)\)</span>.</li>
			<li>Evaluate the three edge functions.</li>
			<li>If inside, call <code>fill_pixel(x, y, color)</code>.</li>
		</ol>

		<h3>Correctness and Complexity Analysis</h3>

		<p>
		<strong>Correctness.</strong>
		The algorithm first computes the triangle’s axis-aligned bounding box, which is guaranteed to contain
		the entire triangle. Therefore, any pixel whose center could be inside the triangle must lie within this box,
		and it is sufficient to only test samples in this region.
		</p>

		<p>
		For each pixel <span class="math">\( (x, y) \)</span> in the bounding box, the algorithm samples at the pixel center
		<span class="math">\( (x + 0.5,\, y + 0.5) \)</span> and evaluates three edge functions—one per triangle edge.
		Each edge function corresponds to a half-plane test: it returns a signed value indicating whether the sample lies
		to the left or right of a directed edge. A point is inside the triangle if it lies on the “inside” side of
		<em>all three</em> edges. To support both clockwise and counter-clockwise vertex orderings, the code checks the sign of the
		triangle’s signed area and consistently uses either <span class="math">\( \ge 0 \)</span> or
		<span class="math">\( \le 0 \)</span> for all three edges. This ensures that pixels are filled exactly when their centers lie
		inside (or on the boundary of) the triangle.
		</p>

		<p>
		Degenerate triangles (zero area) are handled explicitly by early return, preventing undefined behavior and ensuring
		correctness in edge cases.
		</p>

		<p>
		<strong>Complexity.</strong>
		Let the bounding box have width <span class="math">\(W\)</span> and height <span class="math">\(H\)</span>.
		The algorithm iterates over every integer pixel coordinate in this rectangle, performing a constant amount of work per pixel:
		three edge-function evaluations (each consisting of a small fixed number of multiplies/adds) and a few comparisons.
		Therefore, the total work per triangle is proportional to the number of pixels in the bounding box:
		</p>

		<p>
		<span class="math">\( \Theta(W \cdot H) \)</span>
		</p>

		<p>
		This is asymptotically no worse than any approach that “checks each sample within the bounding box,” since such approaches
		must also visit <span class="math">\(W \cdot H\)</span> samples and do at least constant work per sample.
		The only additional overhead here is the constant-time setup (bounding-box computation, clamping, and a single signed-area
		computation), which does not change the overall runtime.
		</p>

		<figure>
			<img src="task1_images/basic_test4.png" alt="basic_test4" style="width:100%"/>
			<figcaption>Basic Test 4</figcaption>
		</figure>

		<!-- <p>Here is an example 2x2 gridlike structure using an HTML table. Each <b>tr</b> is a row and each <b>td</b> is a column in that row. You might find this useful for framing and showing your result images in an organized fashion.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="lion.jpg" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="lion.jpg" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="lion.jpg" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="lion.jpg" width="400px"/>
				  <figcaption>Caption goes here.</figcaption>
				</td>
			  </tr>
			</table>
		</div> -->
		<h3>Optimizations Beyond Basic Bounding-Box Rasterization</h3>

		<p>
		In addition to the standard bounding box and per-pixel inside test approach, I implemented a
		scanline rasterizer that reduces unnecessary work on pixels that are inside the
		triangle’s bounding box but outside the triangle itself.
		</p>

		<h4>1) Scanline Span Filling (Primary Optimization)</h4>
		<p>
		A basic triangle rasterizer computes the triangle’s axis-aligned bounding box and then, for every pixel
		center in that box, evaluates three edge functions to test whether the sample lies inside the triangle. This can
		waste a significant amount of work when the triangle occupies only a small fraction of its bounding box (e.g.,
		thin or diagonal triangles).
		</p>
		<p>
		Instead, my implementation rasterizes the triangle one scanline at a time. For each integer screen row
		<span class="math">\(y\)</span>, I sample at the pixel-center y-coordinate <span class="math">\(s_y = y + 0.5\)</span>
		and compute the intersection between the horizontal line at <span class="math">\(s_y\)</span> and the triangle’s edges.
		These intersections produce (up to) two x-coordinates, which define a single contiguous covered interval
		<span class="math">\([x_L, x_R]\)</span> on that scanline. I then fill only the pixels whose centers lie within that span.
		</p>

		<h4>2) Half-Open Rule for Robust Edge/Vertex Handling</h4>
		<p>
		To avoid double-counting intersections at shared vertices (which can happen when a scanline passes exactly through
		a vertex), I use a half-open y-interval rule for each edge: the scanline intersects an edge only when
		<span class="math">\(s_y\)</span> lies in <span class="math">\([y_{\min}, y_{\max})\)</span>. Additionally, horizontal edges
		are ignored during intersection. This combination ensures that each scanline typically yields exactly two valid
		intersections and avoids cracks or double-filled rows at triangle boundaries.
		</p>

		<h3>Timing Comparison (Averaged Over 3 Trials)</h3>

		<p>
		To quantify the performance improvement, I measured the average time per triangle
		(in nanoseconds) for both the baseline bounding-box rasterizer (per-pixel edge tests)
		and the optimized scanline span-filling implementation.
		</p>

		<p>
		Each configuration was run over 3 trials, and I report the
		mean time per triangle along with the standard deviation to reflect
		variability between runs.
		</p>

		<table style="border-collapse: collapse; width: 100%; max-width: 1000px;">
		<thead>
			<tr>
			<th style="border: 1px solid #ccc; padding: 8px;">Task</th>
			<th style="border: 1px solid #ccc; padding: 8px;">Triangles</th>
			<th style="border: 1px solid #ccc; padding: 8px;">Baseline Mean (ns/triangle)</th>
			<th style="border: 1px solid #ccc; padding: 8px;">Baseline Std Dev</th>
			<th style="border: 1px solid #ccc; padding: 8px;">Optimized Mean (ns/triangle)</th>
			<th style="border: 1px solid #ccc; padding: 8px;">Optimized Std Dev</th>
			</tr>
		</thead>
		<tbody>
			<tr>
			<td style="border: 1px solid #ccc; padding: 8px;">3</td>
			<td style="border: 1px solid #ccc; padding: 8px;">1800</td>
			<td style="border: 1px solid #ccc; padding: 8px;">2106.75</td>
			<td style="border: 1px solid #ccc; padding: 8px;">90.96</td>
			<td style="border: 1px solid #ccc; padding: 8px;">491.16</td>
			<td style="border: 1px solid #ccc; padding: 8px;">98.49</td>
			</tr>
			<tr>
			<td style="border: 1px solid #ccc; padding: 8px;">4</td>
			<td style="border: 1px solid #ccc; padding: 8px;">5</td>
			<td style="border: 1px solid #ccc; padding: 8px;">77655.67</td>
			<td style="border: 1px solid #ccc; padding: 8px;">6565.96</td>
			<td style="border: 1px solid #ccc; padding: 8px;">37947.27</td>
			<td style="border: 1px solid #ccc; padding: 8px;">409.48</td>
			</tr>
			<tr>
			<td style="border: 1px solid #ccc; padding: 8px;">5</td>
			<td style="border: 1px solid #ccc; padding: 8px;">6</td>
			<td style="border: 1px solid #ccc; padding: 8px;">175592.67</td>
			<td style="border: 1px solid #ccc; padding: 8px;">17091.72</td>
			<td style="border: 1px solid #ccc; padding: 8px;">75865.70</td>
			<td style="border: 1px solid #ccc; padding: 8px;">3489.67</td>
			</tr>
			<tr>
			<td style="border: 1px solid #ccc; padding: 8px;">6</td>
			<td style="border: 1px solid #ccc; padding: 8px;">120</td>
			<td style="border: 1px solid #ccc; padding: 8px;">5238.05</td>
			<td style="border: 1px solid #ccc; padding: 8px;">217.34</td>
			<td style="border: 1px solid #ccc; padding: 8px;">2031.47</td>
			<td style="border: 1px solid #ccc; padding: 8px;">47.04</td>
			</tr>
		</tbody>
		</table>

		<p>
		The results show a consistent performance improvement across all tasks. The relatively small
		standard deviations indicate stable performance across trials. The scanline span-filling
		method significantly reduces unnecessary per-pixel edge tests inside the bounding box.
		</p>
		
		<h2>Task 2: Antialiasing by Supersampling</h2>
		<p>
		Supersampling is useful because it gives a better estimate of a pixel's true color by sampling
		multiple locations inside the pixel and averaging them. This matters most for high-frequency content, 
		especially triangle edges. On these edges, with only one sample per pixel, many pixels on the boundary of the edge 
		flip between being inside and outside the triangle, causing aliasing. With more samples per pixel (supersampling), 
		the boundary pixels become partially covered, so their averaged color becomes a smoother blend, making the edges
		appear smoother.
		</p>
		<p>
		To implement supersampling, I rasterized primitives into a higher-resolution sample buffer rather than
		writing directly to the framebuffer. This sample buffer is treated as a virtual framebuffer of size width * n by height * n.
		In rasterize_triangle, I evaluated coverage at each subsample location, and if the subsample lies inside the triangle, I wrote
		the color to the corresponding position in sample_buffer. For points and lines, I modified fill_pixel() to fill all subsamples
		of a pixel with the same color so that they rendered correctly without implementing antialiasing. After rasterization,
		resolve_to_framebuffer() averaged the n x n subsamples for each pixel and wrote the averaged color to the actual framebuffer.
		This allows edges of triangles to be blurred, visualizing the partial coverage of boundary pixels and acting as an antialiasing filter.
		</p>

		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="task2_images/1.png" width="400px"/>
				  <figcaption>Sampling Rate 1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="task2_images/4.png" width="400px"/>
				  <figcaption>Sampling Rate 4</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="task2_images/16.png" width="400px"/>
				  <figcaption>Sampling Rate 16</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h2>Task 3: Transforms</h2>
		<p>
		For this task, I posed Cubeman in a jumping jack position: arms raised out to the sides 
		and legs spread wide.
		</p>

		<p>
		I also recolored Cubeman: a two-tone steel-blue torso, a gold diamond head with a cyan 
		visor accent, teal arms, and crimson legs. Each body part uses a darker and lighter 
		triangle for the same polygon shape.
		</p>

		<div align="middle">
		<img src="task3_images/my_robot.png" align="middle" width="400px"/>
		<figcaption align="middle">Cubeman mid-jumping-jack: arms raised outward, legs spread wide.</figcaption>
		</div>

		<p>
		The key challenge was rotating each limb around its joint rather than its center. 
		Since SVG rotations pivot around the current local origin, I first 
		<code>translate()</code> to the joint position, then <code>rotate()</code>, then place 
		the segment geometry offset from that pivot. For example, the hip joint sits at 
		<code>y = 60</code> because the upper-leg segment is centered at <code>y = 90</code> 
		with a half-height of 30 (derived from <code>scale(0.2, 0.6)</code> on a ±50 unit 
		square), so the top of the segment (the hip) lands at <code>90 − 30 = 60</code>. 
		The same logic horizontally gives the shoulder at <code>x = ±60</code> for the arms.
		</p>

		<p>
		With the pivots correctly placed, the left leg rotates <code>+35°</code> and the right 
		leg <code>−30°</code>, spreading the legs outward from the body's center line. The arms 
		mirror this symmetry: the left arm rotates <code>+35°</code> and the right arm 
		<code>−35°</code>, angling both upward and away from the torso. The result is a 
		bilaterally symmetric pose that reads immediately as a jumping jack mid-motion.
		</p>

		<h3>Extra Credit: Viewport Rotation (GUI Feature)</h3>

		<h4>Feature Overview</h4>
		<p>
		For the extra credit, I added a viewport rotation feature to the GUI. Using two previously unused
		keys, the user can rotate the entire view of the SVG canvas in fixed increments.
		</p>

		<ul>
		<li><strong>[</strong> rotates the viewport counterclockwise by 5 degrees</li>
		<li><strong>]</strong> rotates the viewport clockwise by 5 degrees</li>
		</ul>

		<h4>Implementation Details</h4>

		<h5>1) Adding new keybindings</h5>
		<p>
		I implemented the new controls in <code>DrawRend::keyboard_event</code>. On key press, I update a member variable
		<code>viewport_deg</code> and trigger a redraw:
		</p>
		<pre><code>case '[':
		viewport_deg += 5.0f;
		redraw();
		break;

		case ']':
		viewport_deg -= 5.0f;
		redraw();
		break;</code></pre>

		<h5>2) Modifying the SVG → NDC → Screen transform</h5>
		<p>
		The core idea is that the renderer already uses a matrix stack to map SVG coordinates to screen coordinates:
		</p>
		<pre><code>screen_pos = ndc_to_screen * svg_to_ndc * svg_pos</code></pre>

		<p>
		I inserted an additional viewport rotation matrix between <code>ndc_to_screen</code> and
		<code>svg_to_ndc</code>. This makes the rotation act in NDC space, meaning it rotates the entire
		normalized view (the <span class="math">\([0,1]^2\)</span> canvas) rather than rotating individual SVG objects.
		</p>

		<p>
		A direct rotation in NDC would rotate about the origin (0,0), which would swing the image out of view. To rotate
		about the center of the viewport instead, I used the standard pivot trick:
		</p>

		<p class="math">
		\[
			M_{\text{viewport}} = T(0.5, 0.5)\; R(\theta)\; T(-0.5, -0.5)
		\]
		</p>

		<p>
		This translates the NDC center to the origin, rotates by <span class="math">\(\theta\)</span>, and then translates back.
		In code, I constructed:
		</p>

		<pre><code>Matrix3x3 viewport_rot =
		translate(0.5f, 0.5f) *
		rotate(viewport_deg) *
		translate(-0.5f, -0.5f);</code></pre>

		<p>
		Then I applied it in the draw call:
		</p>

		<pre><code>svg.draw(software_rasterizer, ndc_to_screen * viewport_rot * svg_to_ndc[current_svg]);</code></pre>

		<h5>3) Rotating the canvas outline consistently</h5>
		<p>
		The canvas outline is drawn manually using line rasterization. To keep the outline aligned with the rotated viewport,
		I applied the same matrix stack to the four SVG-space corners.
		This ensures both the scene and the border are transformed identically, so the border continues to correctly frame the
		SVG canvas even as the view rotates.
		</p>

		<h4>Results</h4>
		<div align="middle">
		<img src="task3_images/ec.png" align="middle" width="400px"/>
		</div>

		<h2>Task 4: Barycentric coordinates</h2>
		<p>
			Barycentric coordinates are a way of expressing any point inside a triangle as a weighted combinationof the 
			triangle's 3 vertices. Given a triangle with vertices 
			<span class="math">\((v0, v1, v2)\)</span>, any point <span class="math">\(p\)</span> can be represented as:
			p = w0 * v0 + w1 * v1 + w2 * v2
			where <span class="math">\(w0, w1, w2\)</span> are the barycentric coordinates that sum to 1, and with all 
			weights being non-negative for points inside the triangle. These 3 weights tell us how close the point is to
			each of the vertices, allowing us to interpolate attributes such as color from the triangle vertices.

			In this image, the area near the red vertex appears mostly red, and similarly for the other colors/vertices.
			The center is a blend of red, green, and blue, as it is a mix of all 3 vertices. This is since the closer we 
			are to a given vertex, the larger the weight corresponding to that vertex is in barycentric coordinates,
			and thus the larger the contribution of that vertex's color to the final interpolated color at that point. The center 
			of the triangle is an even blend of all 3 vertices as all 3 weights are equal, and points on any of the 3 vertices
			are the pure color of that vertex, as its weight for that verex is 1 and all other weights 0.
		</p>

		<figure style="text-align: center;">
			<img src="task4_images/writeup_aid.png" alt="Barycentric coordinates visualization" style="width:30%"/>
			<figcaption>Barycentric coordinates interpolation, colors blend smoothly from each vertex.</figcaption>
		</figure>

		<figure style="text-align: center;">
			<img src="task4_images/basic_test7.png" alt="basic_test7" style="width:50%"/>
			<figcaption>Basic Test 7, sample rate = 1</figcaption>
		</figure>

		<h2>Task 5: "Pixel sampling" for texture mapping</h2>

		<h3>Overview: What is pixel sampling?</h3>
		<p>
		In texture mapping, each fragment (pixel sample) on the screen corresponds to a continuous texture coordinate
		<span class="math">\( (u, v) \)</span> in the range <span class="math">\([0,1]\times[0,1]\)</span>.
		The texture image, however, is stored as a discrete grid of texels. Pixel sampling is the process of
		converting a continuous <span class="math">\( (u, v) \)</span> coordinate into a color by reading one or more nearby texels.
		The choice of sampling method determines how sharp or smooth the final textured result appears, especially when the
		texture is magnified or minified.
		</p>

		<h3>How I implemented pixel sampling</h3>
		<p>
		In my implementation, <code>Texture::sample</code> selects a pixel sampling method based on <code>sp.psm</code>.
		For this task I used mip level 0 (base level) and focused on pixel sampling behavior:
		</p>

		<pre><code>Color Texture::sample(const SampleParams&amp; sp) {
		int level = 0;
		if (sp.psm == P_NEAREST) {
			return sample_nearest(sp.p_uv, level);
		} else { // P_LINEAR
			return sample_bilinear(sp.p_uv, level);
		}
		}</code></pre>

		<p>
		Both sampling routines clamp <span class="math">\(u\)</span> and <span class="math">\(v\)</span> to
		<span class="math">\([0,1]\)</span> to avoid out-of-bounds accesses, convert the continuous coordinates into texel-space
		coordinates, and then read texel values from the selected mip level.
		</p>

		<h3>Nearest Neighbor Sampling</h3>
		<p>
		Nearest neighbor sampling chooses the single texel whose center is closest to the continuous
		coordinate <span class="math">\( (u, v) \)</span>. Conceptually, it rounds to the nearest integer texel index and
		returns that texel’s color.
		</p>

		<p>
		Implementation details:
		</p>
		<ul>
		<li>Clamp <span class="math">\(u,v\)</span> into <span class="math">\([0,1]\)</span>.</li>
		<li>Map to texel coordinates:
			<span class="math">\(x = u\cdot(\text{width}-1)\)</span>,
			<span class="math">\(y = v\cdot(\text{height}-1)\)</span>.
		</li>
		<li>Round <span class="math">\(x,y\)</span> to the nearest integer texel indices.</li>
		<li>Clamp indices to valid ranges and fetch the texel.</li>
		</ul>

		<pre><code>int tx = (int)round(u * (mip.width  - 1));
		int ty = (int)round(v * (mip.height - 1));
		return mip.get_texel(tx, ty);</code></pre>

		<p>
		Nearest sampling is very fast and preserves hard edges, but it often produces visible “blocky” artifacts when a
		texture is magnified, since each pixel can abruptly switch between texels.
		</p>

		<h3>Bilinear Sampling</h3>
		<p>
		Bilinear sampling smooths these transitions by interpolating between the four texels surrounding
		the continuous coordinate. Instead of picking one closest texel, it computes a weighted average based on how close
		<span class="math">\( (u, v) \)</span> is to each texel corner in texel space.
		</p>

		<p>
		Implementation details:
		</p>
		<ul>
		<li>Clamp <span class="math">\(u,v\)</span> into <span class="math">\([0,1]\)</span>.</li>
		<li>Compute continuous texel-space position:
			<span class="math">\(x = u\cdot(\text{width}-1)\)</span>,
			<span class="math">\(y = v\cdot(\text{height}-1)\)</span>.
		</li>
		<li>Compute the surrounding integer texel indices:
			<span class="math">\(x_0=\lfloor x\rfloor\)</span>,
			<span class="math">\(x_1=\min(x_0+1,\text{width}-1)\)</span>,
			and similarly for <span class="math">\(y_0,y_1\)</span>.
		</li>
		<li>Compute interpolation weights:
			<span class="math">\(s_x = x-x_0\)</span>,
			<span class="math">\(s_y = y-y_0\)</span>.
		</li>
		<li>Fetch <span class="math">\(c_{00},c_{10},c_{01},c_{11}\)</span> and interpolate first in x, then in y.</li>
		</ul>

		<pre><code>Color c0 = c00 * (1.0f - sx) + c10 * sx;
		Color c1 = c01 * (1.0f - sx) + c11 * sx;
		return c0 * (1.0f - sy) + c1 * sy;</code></pre>

		<h3>Pixel Sampling Comparison (Nearest vs. Bilinear)</h3>

		<h4>Chosen Example Region</h4>
		<p>
		To find a clear case where bilinear sampling outperforms nearest sampling, I used the pixel inspector on
		<code>svg/texmap/test4.svg</code> and zoomed into the parrot texture. I specifically focused on the parrot’s
		black eye stripes, since they contain thin, high-contrast details (dark lines adjacent to bright colors)
		that are very sensitive to how texture lookups are filtered during magnification.
		</p>

		<h4>Screenshots</h4>
		<p>
		Below are four screenshots of the <em>same zoomed-in region</em> (parrot eye stripes) under different settings:
		</p>

		<ul>
		<li>Nearest sampling, 1 sample per pixel (1 spp)</li>
		<li>Nearest sampling, 16 samples per pixel (16 spp)</li>
		<li>Bilinear sampling, 1 sample per pixel (1 spp)</li>
		<li>Bilinear sampling, 16 samples per pixel (16 spp)</li>
		</ul>

		<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 12px; max-width: 1100px;">
		<figure style="margin: 0;">
			<img src="task5_images/nearest_1.png" alt="Nearest sampling at 1 sample per pixel" style="width: 100%; height: auto; border: 1px solid #ccc;">
			<figcaption><strong>Nearest, 1 spp</strong></figcaption>
		</figure>

		<figure style="margin: 0;">
			<img src="task5_images/nearest_16.png" alt="Nearest sampling at 16 samples per pixel" style="width: 100%; height: auto; border: 1px solid #ccc;">
			<figcaption><strong>Nearest, 16 spp</strong></figcaption>
		</figure>

		<figure style="margin: 0;">
			<img src="task5_images/bilinear_1.png" alt="Bilinear sampling at 1 sample per pixel" style="width: 100%; height: auto; border: 1px solid #ccc;">
			<figcaption><strong>Bilinear, 1 spp</strong></figcaption>
		</figure>

		<figure style="margin: 0;">
			<img src="task5_images/bilinear_16.png" alt="Bilinear sampling at 16 samples per pixel" style="width: 100%; height: auto; border: 1px solid #ccc;">
			<figcaption><strong>Bilinear, 16 spp</strong></figcaption>
		</figure>
		</div>

		<h4>Relative Differences</h4>
		<ul>
		<li>
			Nearest sampling produces a visibly blocky/pixelated appearance in the stripes.
			Because nearest sampling chooses a single closest texel per lookup, small changes in screen position can cause
			sudden jumps between texels. This creates harsh stair-step transitions and makes thin stripes look chunky.
		</li>
		<li>
			Bilinear sampling makes the stripes look smoother and more continuous.
			Since bilinear sampling interpolates between the four surrounding texels, the transition between dark stripe texels
			and nearby lighter texels is blended rather than abruptly switching. This reduces visible texel boundaries and
			preserves the perceived shape of the thin stripe details during magnification.
		</li>
		</ul>

		<p>
		Changing the supersample rate (1 spp to 16 spp) affects a different kind of aliasing:
		</p>
		<ul>
		<li>
			Increasing to 16 spp primarily improves edge aliasing (i.e., jagged boundaries of polygons/triangles),
			because it averages multiple subpixel samples per pixel.
		</li>
		<li>
			However, supersampling does not eliminate the blockiness of nearest texture filtering. In the nearest
			16 spp screenshot, the triangle edges may look smoother than nearest 1 spp, but the parrot’s stripe texture still
			shows discontinuous texel steps because each lookup still snaps to a single texel.
		</li>
		<li>
			The best result is bilinear at 16 spp, which combines smoother texture interpolation (bilinear) with reduced
			geometric aliasing (supersampling). This makes both the stripe details and nearby edges appear cleaner.
		</li>
		</ul>

		<h4>When the difference is large (and why)</h4>
		<p>
		The difference between nearest and bilinear sampling is largest when the texture contains
		high-frequency detail (thin lines, sharp contrast boundaries, small patterns) and the texture is being
		magnified on screen. In these cases, a single pixel may map to a texture coordinate that lies between
		multiple texels, and nearest sampling will group to one texel, creating blocky images.
		</p>

		<p>
		Bilinear sampling reduces this because it approximates the underlying continuous image by blending between
		neighboring texels. This produces smoother intensity transitions and prevents abrupt changes in appearance as the
		sampling location moves slightly across the texture.
		</p>

		<p>
		In contrast, if the texture is very smooth/low-frequency (gradients, large uniform regions), or if the texture is
		close to 1:1 mapping with screen pixels, the difference between nearest and bilinear will be much smaller because
		adjacent texels are already similar and snapping between them is less noticeable.
		</p>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		<p>
			Level sampling is choosing which mipmap level of a texture to use when drawing a textured triangle.
			Mipmaps are the precomputed, downsampled copies of a texture. They are used to improve performance and 
			reduce aliasing when textures are minified, as rather than downsampling the original texture or simply using the original
			texture, we just look up the corresponding level in the mipmap. However it is often difficult to determine which mip level 
			to use, which is where level sampling comes in.
		</p>
		<p>
			For my implementation, for each pixel center in the textured triangle, I computed the barycentric
			coordinates and used them to interpolate the UV coordinates (p.uv) at that pixel. I then computed the UV at
			points 1 unit offset in the x and y directions from p.uv to estimate the derivative of the UV coordinates.
			I then scaled these derivatives by the texture size to convert to texel units, and took the maximum of
			the absolute values of the x and y derivatives, taking the log of that maximum as in lecture to compute the mip level.
			For L_NEAREST, the mip level is simply rounded to the nearest mip level. For L_LINEAR, I used the fractional part of the
			mip level as the interpolated weight between the 2 nearest mip levels, and interpolated the sampled colors from these 2 mip levels.
		</p>
		<p>
			Pixel sampling affects how we sample within a chosen mip level (or level 0 if not using mipmaps). It 
			is the cheapest option in terms of performance, as P_NEAREST requires only 1 texel fetch. P_LINEAR is slightly more 
			expensive with 4 texel fetches and interpolation while reducing aliasing by smoothing transitions. Both require
			no additional memory, and P_LINEAR helps mainly with aliasing due to magnification.
		</p>
		<p>
			Level sampling is slightly more computationally expensive than nearest pixel sampling as it requires computing
			the mipmap level and potentially sampling from 2 mip levels (depending on type of level sampling used). It also requires
			significatn extra memory to store the mipmap. However it is very effective at reducing aliasing due to
			minification, or shimmering/moire due to shrinking textures on the screen.
		</p>
		<p>
			Number of samples per pixel, or supersampling is often the slowest (dependent on the sample rate). This is because
			it requires first rasterizing the triangle at a higher resolution, making the algorithm iterate over significantly
			more pixels. It also has the largest increase in memory usage as the sample buffer scales with the sample rate.
			It has the antialiasing benefit of smoothing jagged edges of triangles, though does not help with texture aliasing.
		</p>

		<h3>Level and Pixel Sampling Comparison</h3>
		<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 12px; max-width: 1100px;">
		<figure style="margin: 0;">
			<img src="task6_images/Lzero_Pnearest.png" alt="Level Zero, Pixel Nearest" style="width: 100%; height: auto; border: 1px solid #ccc;">
			<figcaption><strong>L_ZERO, P_NEAREST</strong></figcaption>
		</figure>

		<figure style="margin: 0;">
			<img src="task6_images/Lzero_Plinear.png" alt="Level Zero, Pixel Linear" style="width: 100%; height: auto; border: 1px solid #ccc;">
			<figcaption><strong>L_ZERO, P_LINEAR</strong></figcaption>
		</figure>

		<figure style="margin: 0;">
			<img src="task6_images/Lnearest_Pnearest.png" alt="Level Nearest, Pixel Nearest" style="width: 100%; height: auto; border: 1px solid #ccc;">
			<figcaption><strong>L_NEAREST, P_NEAREST</strong></figcaption>
		</figure>

		<figure style="margin: 0;">
			<img src="task6_images/Llinear_Plinear.png" alt="Level Linear, Pixel Linear" style="width: 100%; height: auto; border: 1px solid #ccc;">
			<figcaption><strong>L_LINEAR, P_LINEAR</strong></figcaption>
		</figure>
		</div>
		</div>
	</body>
</html>